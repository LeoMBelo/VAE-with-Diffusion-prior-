{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código VAE with diffusion prior - Versão simplificada\n",
    "\n",
    "* Obs: Deixei o código mais comentado para esse caso.\n",
    "\n",
    "## Parte 1: DDPM prior\n",
    "\n",
    "### a) Timestep embedding\n",
    "* O objetivo é gerar uma representação contínua dos timesteps (por exemplo, 0, 1, …, T-1), convertendo eles em vetores contínuos por meio de funções trigonométricas (seno e cosseno)\n",
    "\n",
    "* ***Equações do Positional encoding***:\n",
    "Para uma posição $pos$ e uma dimensão $i$ do embedding:\n",
    "$$ \n",
    "PE(pos,2i) = sin(\\frac{pos}{1000^{2i/d_{model}}})\n",
    "$$\n",
    "    \n",
    "$$ \n",
    "PE(pos,2i+1) = cos(\\frac{pos}{1000^{2i/d_{model}}}),\n",
    "$$\n",
    "\n",
    "onde:\n",
    "    * $pos$ seria o timestep (ou a posição) que queremos codificar;\n",
    "    * $d_{model}$ é a dimensão total do embedding;\n",
    "    * e para cada par de dimensões (uma para o seno e outra para o cosseno), o denominador $1000^{2i/d_{model}}$ garante que cada dimensão do embedding corresponde a uma frequência diferente.\n",
    "    \n",
    "* A codificação sinusoidal permite que o modelo saiba a posição (ou, no nosso caso, o timestep) usando funções senoidais e cosenoidais em diferentes frequências.\n",
    "\n",
    "* Referências:\n",
    "    * Denoising Diffusion Probabilistic Models (2020)\n",
    "    * Attention is all you need (2023)\n",
    "\n",
    "### c) DDPM loss\n",
    "* Para cada amostra de z0 (latent extraído pelo encoder):\n",
    "    1. Amostra um timestep t aleatório (de 0 a T-1).\n",
    "    2. Calcula z_t = sqrt(prod_alpha[t]) * z0 + sqrt(1 - prod_alpha[t]) * epsilon,\n",
    "         onde epsilon é ruído gaussiano.\n",
    "    3. O modelo diffusion_prior tenta prever esse epsilon a partir de z_t e t.\n",
    "    4. A loss é o erro quadrático médio (MSE) entre o ruído previsto e o ruído real.\n",
    "    \n",
    "* Equação do artigo:\n",
    "$$ L_{DDPM} (x_0, \\phi) = E_{t,x_0,x_t} [\\frac{1}{2 \\sigma_t ^2} ||\\mu_\\phi(x_t,t) - \\tilde{\\mu}_t(x_0,x_t)||^2],\n",
    "$$\n",
    "onde $\\tilde{\\mu}_t(x_0,x_t)$ é a média de $q(x_{t-1}|x_0,x_t)$, a forward diffusion posterior condicionada na observação $x_0$, $\\mu_\\phi(x_t,t)$ média prevista pelo modelo para o processo reverso e $\\sigma_t ^2$ é a variância associada ao passo t.\n",
    "\n",
    "\n",
    "* Efetuaremos uma reparametrização para usar o ruído no lugar de $\\mu$, ou seja, se parametrizarmos o processo reverso de forma adequada, essa diferença entre as médias pode ser reescrita como a diferença entre o ruído real $\\epsilon$ e uma predição do modelo: $||\\mu_\\phi(x_t,t) - \\tilde{\\mu}_t(x_0,x_t)||^2 \\propto ||\\epsilon_\\phi(x_t,t) - \\epsilon||^2$, onde $\\epsilon_\\phi(x_t,t)$ é a predição do ruído pelo modelo.\n",
    "    * A reparametrização usada é $z_t = \\sqrt{\\Pi_{s=0} ^t \\alpha_s}z_0 + \\sqrt{1-\\Pi_{s=0} ^t \\alpha_s} \\epsilon$, onde $z_0$ é a amostra do espaço latente (obtida do encoder), $\\alpha_s = 1 - \\beta_s$ (note que $\\alpha_s$ representa a proporção da informação original que permanece após a adição de ruído naquele passo) e $\\epsilon$ é amostrado de $N(0,I)$.\n",
    "    * Tal formulação permite que a amostragem seja diferenciável.\n",
    "    * Dessa forma, ao treinar o modelo para prever o ruído $\\epsilon$ (por meio do MSE), garantimos que a aprendizagem está focada em como remover o ruído do estado atual $z_t$.\n",
    "    \n",
    "    \n",
    "## Parte 2: VAE\n",
    "\n",
    "### a) Encoder\n",
    "* Responsável por levar os dados até o espaço latente.\n",
    "* Usaremos duas redes convolucionais e calcularemos, usando camadas lineares, $\\mu$ e $log \\sigma^2$ da distribuição $q(z|x)$\n",
    "* As duas saídas serão usadas para a reparametrização, onde amostramos $z$ a partir de $q(z|x)$.\n",
    "\n",
    "\n",
    "### b) Decoder\n",
    "* Responsável por levar do espaço latente até a reconstrução de imagens $(\\hat{x})$.\n",
    "* Primeiro, o vetor $z$ é transformado por uma camada linear e, em seguida, é desachatado.\n",
    "* Usaremos duas redes convolucionais e usamos a função de ativação sigmoid de modo a garantir uma saída no intervalo [0,1], assim como estão as imagens normalizadas. \n",
    "\n",
    "\n",
    "### c) Reparametrização\n",
    "* Usamos a equação $z = \\mu(x) + \\sigma(x) \\odot \\epsilon$, ou seja, $z_i = \\mu_i + \\sigma_i . \\epsilon_i$\n",
    "\n",
    "## Parte 3: Loss treinamento\n",
    "* No artigo principal, a loss é dada por:\n",
    "$$ \\mathcal{L}(x;\\phi, \\theta, \\psi) = E_{q_\\psi}[log \\frac{p_\\theta(x|z)}{q_\\psi (z|x)}] + E_{q_\\psi} [L_{DDPM}(z_0;\\phi)],\n",
    "$$\n",
    "onde $q_\\psi(z|x)$ é a distribuição aproximada do encoder, $p_\\theta (x|z)$ é o modelo de verossimilhança do decoder.\n",
    "\n",
    "* De certo modo, a loss é escrita da forma: $Loss = reconstructed_{Loss} + Latent_{Loss}$.\n",
    "    * A ***recon_loss*** é calculada como a Binary Cross-Entropy entre a imagem reconstruída e a imagem original.\n",
    "    * A ***latent_loss***  é calculada a partir da loss de difusão. Essa parte substitui o termo tradicional da KL divergence.\n",
    "    \n",
    "* Lembrando que a função loss de difusão faz:\n",
    "    1. A partir de $z_0$, é gerado o $z_t$ usando o forward do DDPM: $z_t = \\sqrt{\\Pi_{s=0} ^t \\alpha_s}z_0 + \\sqrt{1-\\Pi_{s=0} ^t \\alpha_s} \\epsilon$, com $\\epsilon \\sim N(0,I)$.\n",
    "    2. O diffusion prior $(\\epsilon_\\phi(z_t,t))$ tenta prever o ruído $\\epsilon$.\n",
    "    3. A loss é o erro quadrático médio (MSE) entre a predição do ruído e o ruído real: $DDPM_{loss} = ||\\epsilon_\\phi(z_t,t) - \\epsilon||^2$\n",
    "    \n",
    "# Por que simplificada?\n",
    "* Pouco uso da estrutura DCGAN\n",
    "    * Redes mais simples sem Batch Normalization e poucas camadas\n",
    "* Betas fixos e lineares\n",
    "* Função de ativação padrão no prior DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Parametros\n",
    "hidden_dim=128\n",
    "time_embed_dim=64\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "############ DDPM ###################\n",
    "#Variance schedule (fixed)\n",
    "def beta_schedule(T,start=1e-4,end=2e-2):\n",
    "    return torch.linspace(start, end, T)\n",
    "\n",
    "#Positional encoding in timestep embedding\n",
    "def timestep_embedding(timesteps, embedding_dim):\n",
    "    \"\"\"\n",
    "    * Cria uma embedding sinusoidal para os timesteps, similar ao positional encoding.\n",
    "        - Gera uma representação fixa e contínua dos timesteps\n",
    "    * Funções:\n",
    "        - Ao concatenar o timestep com a entrada (ex: vetor ruidoso z_t), o modelo recebe uma indicação \n",
    "        explícita de quanta informação foi degradada ou, inversamente, quanto “limpo” o vetor ainda é.\n",
    "        - Usar vetores contínuos ajuda a rede a lidar com diferentes escalas de tempo sem a \n",
    "        necessidade de ter um parâmetro distinto para cada passo, tornando o modelo mais estável e eficiente.\n",
    "    \"\"\"\n",
    "    half_dim = embedding_dim // 2 #separa a dimensão em duas partes: uma para cos e outra para seno\n",
    "    # Calcula os coeficientes exponenciais para a embedding\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -(math.log(10000.0) / (half_dim - 1)))\n",
    "        ## Gera ângulo (pos,i) = pos x 1000 ^{-i/{half_dim - 1}}\n",
    "    emb = timesteps.float().unsqueeze(1) * emb.unsqueeze(0)  # [batch, half_dim]\n",
    "        ## Calcula seno e cos (as primeiras half_dim posiçôes são para os senos e as outras para os cossenos)\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "    if embedding_dim % 2 == 1:  # se a dimensão for ímpar, completa com zeros (garante forma correta)\n",
    "        emb = torch.cat([emb, torch.zeros(timesteps.size(0), 1, device=emb.device)], dim=1)\n",
    "    return emb\n",
    "\n",
    "\n",
    "class DiffusionPrior(nn.Module):\n",
    "    def __init__(self, latent_dim, time_embed_dim=time_embed_dim, hidden_dim=hidden_dim):\n",
    "        super(DiffusionPrior, self).__init__()\n",
    "        #Nenhuma camada interna\n",
    "        self.fc1 = nn.Linear(latent_dim + time_embed_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, latent_dim)\n",
    "    \n",
    "    def forward(self, z_t, t):\n",
    "        # Obtém a embedding do timestep para cada amostra\n",
    "        t_embed = timestep_embedding(t, self.fc1.in_features - z_t.size(1))\n",
    "        # Concatena a representação ruidosa z_t com a embedding do tempo\n",
    "        x = torch.cat([z_t, t_embed], dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        noise_pred = self.fc2(x)\n",
    "        return noise_pred\n",
    "\n",
    "#loss ddpm\n",
    "def ddpm_loss(diffusion_prior, z0, betas, alpha_bars, T):\n",
    "    batch_size, latent_dim = z0.shape\n",
    "    device = z0.device\n",
    "    # Amostra um timestep t para cada exemplo no batch\n",
    "    t = torch.randint(0, T, (batch_size,), device=device)\n",
    "    # Recupera alpha_bar correspondente a cada t e ajusta o shape\n",
    "    alpha_bar_t = alpha_bars[t].view(-1, 1)  # [batch, 1]\n",
    "    # Amostra o ruído epsilon ~ N(0,I)\n",
    "    epsilon = torch.randn_like(z0)\n",
    "    # Calcula z_t conforme a fórmula do forward process do DDPM\n",
    "        #alpha_bar_t = prod_alpha (0 até t)\n",
    "    z_t = torch.sqrt(alpha_bar_t) * z0 + torch.sqrt(1 - alpha_bar_t) * epsilon\n",
    "    # Prediz o ruído a partir de z_t e do timestep\n",
    "    noise_pred = diffusion_prior(z_t, t)\n",
    "    # Calcula o MSE entre o ruído real e o previsto\n",
    "    loss = F.mse_loss(noise_pred, epsilon)\n",
    "    return loss\n",
    "\n",
    "# MNIST: imagens 1x28x28\n",
    "############ VAE ###################\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        # Para MNIST: entrada 1x28x28\n",
    "            # kernel_size = 4\n",
    "            # stride = 2\n",
    "            # padding = 1\n",
    "            # dim_output = (28 - 4 + 2 x 1)/2 + 1 = 14 \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1)  # -> 32x14x14\n",
    "            # kernel_size = 4\n",
    "            # stride = 2\n",
    "            # padding = 1\n",
    "            # dim_output = (14 - 4 + 2 x 1)/2 + 1 = 7\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1) # -> 64x7x7\n",
    "        self.fc_mu = nn.Linear(64 * 7 * 7, latent_dim) #fc: fully connected (linear)\n",
    "        self.fc_logvar = nn.Linear(64 * 7 * 7, latent_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(batch_size, -1)  # Flatten: ([batch_size,1,28,28] virou [batch_size, 1x28x28])\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Linear(latent_dim, 64 * 7 * 7)\n",
    "        self.deconv1 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)  # -> 32x14x14\n",
    "        self.deconv2 = nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1)   # -> 1x28x28\n",
    "    \n",
    "    def forward(self, z):\n",
    "        batch_size = z.size(0)\n",
    "        x = self.fc(z)\n",
    "        x = x.view(batch_size, 64, 7, 7)\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = torch.sigmoid(self.deconv2(x))  # para imagens normalizadas entre 0 e 1\n",
    "        return x\n",
    "\n",
    "# Reparametrização\n",
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "#Parametros\n",
    "latent_dim = 32      # Dimensão do espaço latente\n",
    "T = 100              # Número de passos de difusão\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Cria a schedule de betas e calcula alphas e alpha_bars\n",
    "betas = beta_schedule(T).to(device)         \n",
    "alphas = 1 - betas                               \n",
    "alpha_bars = torch.cumprod(alphas, dim=0)         \n",
    "\n",
    "#Inicialização\n",
    "encoder = Encoder(latent_dim).to(device)\n",
    "decoder = Decoder(latent_dim).to(device)\n",
    "diffusion_prior = DiffusionPrior(latent_dim).to(device)\n",
    "\n",
    "#Otimizador em todos os parametros conjuntamente\n",
    "optimizer = optim.Adam(list(encoder.parameters()) +\n",
    "                       list(decoder.parameters()) +\n",
    "                       list(diffusion_prior.parameters()), lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leomi\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Batch 0/469 - Loss: 523.2589\n",
      "Epoch [1/50] Batch 100/469 - Loss: 134.7588\n",
      "Epoch [1/50] Batch 200/469 - Loss: 93.7495\n",
      "Epoch [1/50] Batch 300/469 - Loss: 74.7373\n",
      "Epoch [1/50] Batch 400/469 - Loss: 73.7314\n",
      "Epoch [1/50] Average Loss: 112.3108\n",
      "Epoch [2/50] Batch 0/469 - Loss: 68.6722\n",
      "Epoch [2/50] Batch 100/469 - Loss: 69.2231\n",
      "Epoch [2/50] Batch 200/469 - Loss: 66.3275\n",
      "Epoch [2/50] Batch 300/469 - Loss: 65.7662\n",
      "Epoch [2/50] Batch 400/469 - Loss: 63.8274\n",
      "Epoch [2/50] Average Loss: 65.7949\n",
      "Epoch [3/50] Batch 0/469 - Loss: 65.3999\n",
      "Epoch [3/50] Batch 100/469 - Loss: 61.8089\n",
      "Epoch [3/50] Batch 200/469 - Loss: 61.3079\n",
      "Epoch [3/50] Batch 300/469 - Loss: 63.7266\n",
      "Epoch [3/50] Batch 400/469 - Loss: 64.8617\n",
      "Epoch [3/50] Average Loss: 62.5186\n",
      "Epoch [4/50] Batch 0/469 - Loss: 61.9283\n",
      "Epoch [4/50] Batch 100/469 - Loss: 61.1236\n",
      "Epoch [4/50] Batch 200/469 - Loss: 62.6423\n",
      "Epoch [4/50] Batch 300/469 - Loss: 60.7558\n",
      "Epoch [4/50] Batch 400/469 - Loss: 61.5425\n",
      "Epoch [4/50] Average Loss: 61.0374\n",
      "Epoch [5/50] Batch 0/469 - Loss: 60.1158\n",
      "Epoch [5/50] Batch 100/469 - Loss: 59.8102\n",
      "Epoch [5/50] Batch 200/469 - Loss: 59.2814\n",
      "Epoch [5/50] Batch 300/469 - Loss: 61.3207\n",
      "Epoch [5/50] Batch 400/469 - Loss: 61.8237\n",
      "Epoch [5/50] Average Loss: 60.1072\n",
      "Epoch [6/50] Batch 0/469 - Loss: 59.0109\n",
      "Epoch [6/50] Batch 100/469 - Loss: 58.8880\n",
      "Epoch [6/50] Batch 200/469 - Loss: 57.7417\n",
      "Epoch [6/50] Batch 300/469 - Loss: 58.9535\n",
      "Epoch [6/50] Batch 400/469 - Loss: 59.3929\n",
      "Epoch [6/50] Average Loss: 59.4620\n",
      "Epoch [7/50] Batch 0/469 - Loss: 58.8080\n",
      "Epoch [7/50] Batch 100/469 - Loss: 60.7937\n",
      "Epoch [7/50] Batch 200/469 - Loss: 59.5070\n",
      "Epoch [7/50] Batch 300/469 - Loss: 60.1899\n",
      "Epoch [7/50] Batch 400/469 - Loss: 60.0835\n",
      "Epoch [7/50] Average Loss: 58.9905\n",
      "Epoch [8/50] Batch 0/469 - Loss: 57.3878\n",
      "Epoch [8/50] Batch 100/469 - Loss: 56.6309\n",
      "Epoch [8/50] Batch 200/469 - Loss: 58.2340\n",
      "Epoch [8/50] Batch 300/469 - Loss: 59.8997\n",
      "Epoch [8/50] Batch 400/469 - Loss: 56.8498\n",
      "Epoch [8/50] Average Loss: 58.5997\n",
      "Epoch [9/50] Batch 0/469 - Loss: 58.3198\n",
      "Epoch [9/50] Batch 100/469 - Loss: 57.7400\n",
      "Epoch [9/50] Batch 200/469 - Loss: 57.7333\n",
      "Epoch [9/50] Batch 300/469 - Loss: 56.1202\n",
      "Epoch [9/50] Batch 400/469 - Loss: 60.4244\n",
      "Epoch [9/50] Average Loss: 58.2840\n",
      "Epoch [10/50] Batch 0/469 - Loss: 57.6607\n",
      "Epoch [10/50] Batch 100/469 - Loss: 58.1331\n",
      "Epoch [10/50] Batch 200/469 - Loss: 56.3292\n",
      "Epoch [10/50] Batch 300/469 - Loss: 56.0628\n",
      "Epoch [10/50] Batch 400/469 - Loss: 55.2303\n",
      "Epoch [10/50] Average Loss: 58.0340\n",
      "Epoch [11/50] Batch 0/469 - Loss: 57.6475\n",
      "Epoch [11/50] Batch 100/469 - Loss: 61.2082\n",
      "Epoch [11/50] Batch 200/469 - Loss: 56.6909\n",
      "Epoch [11/50] Batch 300/469 - Loss: 59.7809\n",
      "Epoch [11/50] Batch 400/469 - Loss: 57.4224\n",
      "Epoch [11/50] Average Loss: 57.8185\n",
      "Epoch [12/50] Batch 0/469 - Loss: 58.4609\n",
      "Epoch [12/50] Batch 100/469 - Loss: 57.3429\n",
      "Epoch [12/50] Batch 200/469 - Loss: 57.0866\n",
      "Epoch [12/50] Batch 300/469 - Loss: 58.7340\n",
      "Epoch [12/50] Batch 400/469 - Loss: 56.4970\n",
      "Epoch [12/50] Average Loss: 57.6176\n",
      "Epoch [13/50] Batch 0/469 - Loss: 56.6895\n",
      "Epoch [13/50] Batch 100/469 - Loss: 57.4098\n",
      "Epoch [13/50] Batch 200/469 - Loss: 57.3646\n",
      "Epoch [13/50] Batch 300/469 - Loss: 55.8984\n",
      "Epoch [13/50] Batch 400/469 - Loss: 57.6078\n",
      "Epoch [13/50] Average Loss: 57.4662\n",
      "Epoch [14/50] Batch 0/469 - Loss: 57.6564\n",
      "Epoch [14/50] Batch 100/469 - Loss: 60.6637\n",
      "Epoch [14/50] Batch 200/469 - Loss: 57.3276\n",
      "Epoch [14/50] Batch 300/469 - Loss: 58.2789\n",
      "Epoch [14/50] Batch 400/469 - Loss: 55.7490\n",
      "Epoch [14/50] Average Loss: 57.3058\n",
      "Epoch [15/50] Batch 0/469 - Loss: 56.9668\n",
      "Epoch [15/50] Batch 100/469 - Loss: 58.6060\n",
      "Epoch [15/50] Batch 200/469 - Loss: 57.9140\n",
      "Epoch [15/50] Batch 300/469 - Loss: 56.2954\n",
      "Epoch [15/50] Batch 400/469 - Loss: 56.9823\n",
      "Epoch [15/50] Average Loss: 57.1848\n",
      "Epoch [16/50] Batch 0/469 - Loss: 55.6520\n",
      "Epoch [16/50] Batch 100/469 - Loss: 58.2839\n",
      "Epoch [16/50] Batch 200/469 - Loss: 55.1443\n",
      "Epoch [16/50] Batch 300/469 - Loss: 57.0784\n",
      "Epoch [16/50] Batch 400/469 - Loss: 57.1495\n",
      "Epoch [16/50] Average Loss: 57.0528\n",
      "Epoch [17/50] Batch 0/469 - Loss: 58.6754\n",
      "Epoch [17/50] Batch 100/469 - Loss: 58.6504\n",
      "Epoch [17/50] Batch 200/469 - Loss: 53.0994\n",
      "Epoch [17/50] Batch 300/469 - Loss: 55.5669\n",
      "Epoch [17/50] Batch 400/469 - Loss: 57.2127\n",
      "Epoch [17/50] Average Loss: 56.9497\n",
      "Epoch [18/50] Batch 0/469 - Loss: 54.4566\n",
      "Epoch [18/50] Batch 100/469 - Loss: 58.7390\n",
      "Epoch [18/50] Batch 200/469 - Loss: 55.4134\n",
      "Epoch [18/50] Batch 300/469 - Loss: 57.4394\n",
      "Epoch [18/50] Batch 400/469 - Loss: 58.3588\n",
      "Epoch [18/50] Average Loss: 56.8597\n",
      "Epoch [19/50] Batch 0/469 - Loss: 55.2602\n",
      "Epoch [19/50] Batch 100/469 - Loss: 57.2378\n",
      "Epoch [19/50] Batch 200/469 - Loss: 58.0772\n",
      "Epoch [19/50] Batch 300/469 - Loss: 57.4211\n",
      "Epoch [19/50] Batch 400/469 - Loss: 55.1367\n",
      "Epoch [19/50] Average Loss: 56.7608\n",
      "Epoch [20/50] Batch 0/469 - Loss: 55.7284\n",
      "Epoch [20/50] Batch 100/469 - Loss: 54.2672\n",
      "Epoch [20/50] Batch 200/469 - Loss: 57.6456\n",
      "Epoch [20/50] Batch 300/469 - Loss: 56.0905\n",
      "Epoch [20/50] Batch 400/469 - Loss: 54.5528\n",
      "Epoch [20/50] Average Loss: 56.6703\n",
      "Epoch [21/50] Batch 0/469 - Loss: 55.7854\n",
      "Epoch [21/50] Batch 100/469 - Loss: 58.3211\n",
      "Epoch [21/50] Batch 200/469 - Loss: 58.2274\n",
      "Epoch [21/50] Batch 300/469 - Loss: 55.7630\n",
      "Epoch [21/50] Batch 400/469 - Loss: 58.0110\n",
      "Epoch [21/50] Average Loss: 56.5882\n",
      "Epoch [22/50] Batch 0/469 - Loss: 54.7801\n",
      "Epoch [22/50] Batch 100/469 - Loss: 57.1635\n",
      "Epoch [22/50] Batch 200/469 - Loss: 52.4033\n",
      "Epoch [22/50] Batch 300/469 - Loss: 57.3598\n",
      "Epoch [22/50] Batch 400/469 - Loss: 58.5664\n",
      "Epoch [22/50] Average Loss: 56.5204\n",
      "Epoch [23/50] Batch 0/469 - Loss: 56.7771\n",
      "Epoch [23/50] Batch 100/469 - Loss: 56.6484\n",
      "Epoch [23/50] Batch 200/469 - Loss: 55.5011\n",
      "Epoch [23/50] Batch 300/469 - Loss: 57.7675\n",
      "Epoch [23/50] Batch 400/469 - Loss: 57.3413\n",
      "Epoch [23/50] Average Loss: 56.4453\n",
      "Epoch [24/50] Batch 0/469 - Loss: 55.4152\n",
      "Epoch [24/50] Batch 100/469 - Loss: 56.6662\n",
      "Epoch [24/50] Batch 200/469 - Loss: 56.0109\n",
      "Epoch [24/50] Batch 300/469 - Loss: 53.6115\n",
      "Epoch [24/50] Batch 400/469 - Loss: 54.9941\n",
      "Epoch [24/50] Average Loss: 56.3835\n",
      "Epoch [25/50] Batch 0/469 - Loss: 57.0223\n",
      "Epoch [25/50] Batch 100/469 - Loss: 55.9760\n",
      "Epoch [25/50] Batch 200/469 - Loss: 55.7242\n",
      "Epoch [25/50] Batch 300/469 - Loss: 56.9636\n",
      "Epoch [25/50] Batch 400/469 - Loss: 58.6666\n",
      "Epoch [25/50] Average Loss: 56.3209\n",
      "Epoch [26/50] Batch 0/469 - Loss: 56.7409\n",
      "Epoch [26/50] Batch 100/469 - Loss: 55.1266\n",
      "Epoch [26/50] Batch 200/469 - Loss: 57.9233\n",
      "Epoch [26/50] Batch 300/469 - Loss: 55.9437\n",
      "Epoch [26/50] Batch 400/469 - Loss: 55.5826\n",
      "Epoch [26/50] Average Loss: 56.2653\n",
      "Epoch [27/50] Batch 0/469 - Loss: 54.1249\n",
      "Epoch [27/50] Batch 100/469 - Loss: 53.2085\n",
      "Epoch [27/50] Batch 200/469 - Loss: 55.9729\n",
      "Epoch [27/50] Batch 300/469 - Loss: 56.1020\n",
      "Epoch [27/50] Batch 400/469 - Loss: 54.0418\n",
      "Epoch [27/50] Average Loss: 56.2144\n",
      "Epoch [28/50] Batch 0/469 - Loss: 54.7520\n",
      "Epoch [28/50] Batch 100/469 - Loss: 55.2642\n",
      "Epoch [28/50] Batch 200/469 - Loss: 54.6808\n",
      "Epoch [28/50] Batch 300/469 - Loss: 57.4039\n",
      "Epoch [28/50] Batch 400/469 - Loss: 57.7446\n",
      "Epoch [28/50] Average Loss: 56.1503\n",
      "Epoch [29/50] Batch 0/469 - Loss: 55.3279\n",
      "Epoch [29/50] Batch 100/469 - Loss: 56.2068\n",
      "Epoch [29/50] Batch 200/469 - Loss: 55.9651\n",
      "Epoch [29/50] Batch 300/469 - Loss: 55.7132\n",
      "Epoch [29/50] Batch 400/469 - Loss: 57.7861\n",
      "Epoch [29/50] Average Loss: 56.1155\n",
      "Epoch [30/50] Batch 0/469 - Loss: 59.6498\n",
      "Epoch [30/50] Batch 100/469 - Loss: 56.2534\n",
      "Epoch [30/50] Batch 200/469 - Loss: 54.3304\n",
      "Epoch [30/50] Batch 300/469 - Loss: 56.4590\n",
      "Epoch [30/50] Batch 400/469 - Loss: 57.3312\n",
      "Epoch [30/50] Average Loss: 56.0622\n",
      "Epoch [31/50] Batch 0/469 - Loss: 54.5158\n",
      "Epoch [31/50] Batch 100/469 - Loss: 57.0185\n",
      "Epoch [31/50] Batch 200/469 - Loss: 56.7587\n",
      "Epoch [31/50] Batch 300/469 - Loss: 56.4076\n",
      "Epoch [31/50] Batch 400/469 - Loss: 56.5375\n",
      "Epoch [31/50] Average Loss: 56.0175\n",
      "Epoch [32/50] Batch 0/469 - Loss: 53.5866\n",
      "Epoch [32/50] Batch 100/469 - Loss: 54.5681\n",
      "Epoch [32/50] Batch 200/469 - Loss: 54.9697\n",
      "Epoch [32/50] Batch 300/469 - Loss: 55.7405\n",
      "Epoch [32/50] Batch 400/469 - Loss: 56.2118\n",
      "Epoch [32/50] Average Loss: 55.9834\n",
      "Epoch [33/50] Batch 0/469 - Loss: 56.0718\n",
      "Epoch [33/50] Batch 100/469 - Loss: 59.7376\n",
      "Epoch [33/50] Batch 200/469 - Loss: 57.8209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50] Batch 300/469 - Loss: 52.7923\n",
      "Epoch [33/50] Batch 400/469 - Loss: 56.6232\n",
      "Epoch [33/50] Average Loss: 55.9265\n",
      "Epoch [34/50] Batch 0/469 - Loss: 57.1152\n",
      "Epoch [34/50] Batch 100/469 - Loss: 56.3295\n",
      "Epoch [34/50] Batch 200/469 - Loss: 55.1200\n",
      "Epoch [34/50] Batch 300/469 - Loss: 57.1285\n",
      "Epoch [34/50] Batch 400/469 - Loss: 56.1428\n",
      "Epoch [34/50] Average Loss: 55.9049\n",
      "Epoch [35/50] Batch 0/469 - Loss: 56.0739\n",
      "Epoch [35/50] Batch 100/469 - Loss: 54.9107\n",
      "Epoch [35/50] Batch 200/469 - Loss: 57.4723\n",
      "Epoch [35/50] Batch 300/469 - Loss: 57.2111\n",
      "Epoch [35/50] Batch 400/469 - Loss: 56.9168\n",
      "Epoch [35/50] Average Loss: 55.8667\n",
      "Epoch [36/50] Batch 0/469 - Loss: 55.7097\n",
      "Epoch [36/50] Batch 100/469 - Loss: 54.4774\n",
      "Epoch [36/50] Batch 200/469 - Loss: 56.4342\n",
      "Epoch [36/50] Batch 300/469 - Loss: 56.7136\n",
      "Epoch [36/50] Batch 400/469 - Loss: 53.6655\n",
      "Epoch [36/50] Average Loss: 55.8308\n",
      "Epoch [37/50] Batch 0/469 - Loss: 57.6015\n",
      "Epoch [37/50] Batch 100/469 - Loss: 54.4855\n",
      "Epoch [37/50] Batch 200/469 - Loss: 57.7131\n",
      "Epoch [37/50] Batch 300/469 - Loss: 55.9493\n",
      "Epoch [37/50] Batch 400/469 - Loss: 57.1490\n",
      "Epoch [37/50] Average Loss: 55.7862\n",
      "Epoch [38/50] Batch 0/469 - Loss: 57.0055\n",
      "Epoch [38/50] Batch 100/469 - Loss: 54.3866\n",
      "Epoch [38/50] Batch 200/469 - Loss: 55.1380\n",
      "Epoch [38/50] Batch 300/469 - Loss: 57.0728\n",
      "Epoch [38/50] Batch 400/469 - Loss: 54.6274\n",
      "Epoch [38/50] Average Loss: 55.7560\n",
      "Epoch [39/50] Batch 0/469 - Loss: 55.4473\n",
      "Epoch [39/50] Batch 100/469 - Loss: 56.2139\n",
      "Epoch [39/50] Batch 200/469 - Loss: 54.9786\n",
      "Epoch [39/50] Batch 300/469 - Loss: 52.6641\n",
      "Epoch [39/50] Batch 400/469 - Loss: 56.2257\n",
      "Epoch [39/50] Average Loss: 55.7327\n",
      "Epoch [40/50] Batch 0/469 - Loss: 53.6646\n",
      "Epoch [40/50] Batch 100/469 - Loss: 56.7873\n",
      "Epoch [40/50] Batch 200/469 - Loss: 56.6030\n",
      "Epoch [40/50] Batch 300/469 - Loss: 54.1961\n",
      "Epoch [40/50] Batch 400/469 - Loss: 54.0620\n",
      "Epoch [40/50] Average Loss: 55.6937\n",
      "Epoch [41/50] Batch 0/469 - Loss: 55.3377\n",
      "Epoch [41/50] Batch 100/469 - Loss: 54.8819\n",
      "Epoch [41/50] Batch 200/469 - Loss: 54.3253\n",
      "Epoch [41/50] Batch 300/469 - Loss: 57.2904\n",
      "Epoch [41/50] Batch 400/469 - Loss: 54.9145\n",
      "Epoch [41/50] Average Loss: 55.6656\n",
      "Epoch [42/50] Batch 0/469 - Loss: 55.6678\n",
      "Epoch [42/50] Batch 100/469 - Loss: 57.6793\n",
      "Epoch [42/50] Batch 200/469 - Loss: 53.8660\n",
      "Epoch [42/50] Batch 300/469 - Loss: 56.1085\n",
      "Epoch [42/50] Batch 400/469 - Loss: 56.6947\n",
      "Epoch [42/50] Average Loss: 55.6370\n",
      "Epoch [43/50] Batch 0/469 - Loss: 55.0660\n",
      "Epoch [43/50] Batch 100/469 - Loss: 52.7702\n",
      "Epoch [43/50] Batch 200/469 - Loss: 57.3292\n",
      "Epoch [43/50] Batch 300/469 - Loss: 57.3120\n",
      "Epoch [43/50] Batch 400/469 - Loss: 55.8200\n",
      "Epoch [43/50] Average Loss: 55.6151\n",
      "Epoch [44/50] Batch 0/469 - Loss: 53.1280\n",
      "Epoch [44/50] Batch 100/469 - Loss: 55.5269\n",
      "Epoch [44/50] Batch 200/469 - Loss: 56.5081\n",
      "Epoch [44/50] Batch 300/469 - Loss: 56.2913\n",
      "Epoch [44/50] Batch 400/469 - Loss: 55.7620\n",
      "Epoch [44/50] Average Loss: 55.5857\n",
      "Epoch [45/50] Batch 0/469 - Loss: 55.1147\n",
      "Epoch [45/50] Batch 100/469 - Loss: 55.7764\n",
      "Epoch [45/50] Batch 200/469 - Loss: 57.5969\n",
      "Epoch [45/50] Batch 300/469 - Loss: 55.1527\n",
      "Epoch [45/50] Batch 400/469 - Loss: 56.8952\n",
      "Epoch [45/50] Average Loss: 55.5596\n",
      "Epoch [46/50] Batch 0/469 - Loss: 54.1580\n",
      "Epoch [46/50] Batch 100/469 - Loss: 54.1614\n",
      "Epoch [46/50] Batch 200/469 - Loss: 55.8382\n",
      "Epoch [46/50] Batch 300/469 - Loss: 57.5387\n",
      "Epoch [46/50] Batch 400/469 - Loss: 55.1024\n",
      "Epoch [46/50] Average Loss: 55.5312\n",
      "Epoch [47/50] Batch 0/469 - Loss: 54.2107\n",
      "Epoch [47/50] Batch 100/469 - Loss: 55.1868\n",
      "Epoch [47/50] Batch 200/469 - Loss: 53.4503\n",
      "Epoch [47/50] Batch 300/469 - Loss: 52.0660\n",
      "Epoch [47/50] Batch 400/469 - Loss: 56.8537\n",
      "Epoch [47/50] Average Loss: 55.5112\n",
      "Epoch [48/50] Batch 0/469 - Loss: 56.3334\n",
      "Epoch [48/50] Batch 100/469 - Loss: 55.1160\n",
      "Epoch [48/50] Batch 200/469 - Loss: 54.1034\n",
      "Epoch [48/50] Batch 300/469 - Loss: 58.3743\n",
      "Epoch [48/50] Batch 400/469 - Loss: 55.6092\n",
      "Epoch [48/50] Average Loss: 55.4943\n",
      "Epoch [49/50] Batch 0/469 - Loss: 55.7465\n",
      "Epoch [49/50] Batch 100/469 - Loss: 53.6395\n",
      "Epoch [49/50] Batch 200/469 - Loss: 53.3641\n",
      "Epoch [49/50] Batch 300/469 - Loss: 54.8207\n",
      "Epoch [49/50] Batch 400/469 - Loss: 53.3819\n",
      "Epoch [49/50] Average Loss: 55.4604\n",
      "Epoch [50/50] Batch 0/469 - Loss: 55.2228\n",
      "Epoch [50/50] Batch 100/469 - Loss: 53.0206\n",
      "Epoch [50/50] Batch 200/469 - Loss: 54.6710\n",
      "Epoch [50/50] Batch 300/469 - Loss: 54.7256\n",
      "Epoch [50/50] Batch 400/469 - Loss: 54.8326\n",
      "Epoch [50/50] Average Loss: 55.4400\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# Sampling no Espaço Latente (Reverse Diffusion)\n",
    "\n",
    "def sample_latent(diffusion_prior, T, latent_dim, betas, alpha_bars, device):\n",
    "    # Inicializa z_T ~ N(0,I)\n",
    "    z = torch.randn((1, latent_dim), device=device)\n",
    "    # Loop reverso: de t = T-1 até 0\n",
    "    for t in reversed(range(1, T)):\n",
    "        t_tensor = torch.full((z.shape[0],), t, device=device, dtype=torch.long)\n",
    "        # Predição do ruído usando o diffusion_prior\n",
    "        pred_noise = diffusion_prior(z, t_tensor)\n",
    "        beta_t = betas[t]\n",
    "        alpha_t = alphas[t]\n",
    "        alpha_bar_t = alpha_bars[t]\n",
    "        # Equação para o passo reverso (simplificada):\n",
    "        z = (z - ((1 - alpha_t) / torch.sqrt(1 - alpha_bar_t)) * pred_noise) / torch.sqrt(alpha_t)\n",
    "        # Se t > 0, adiciona ruído\n",
    "        if t > 0:\n",
    "            noise = torch.randn_like(z)\n",
    "            z = z + torch.sqrt(beta_t) * noise\n",
    "    return z\n",
    "\n",
    "\n",
    "# Inicialização dos Modelos  \n",
    "    #Parametros\n",
    "latent_dim = 32      # Dimensão do espaço latente\n",
    "T = 100              # Número de passos de difusão\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Cria a schedule de betas e calcula alphas e alpha_bars\n",
    "betas = beta_schedule(T).to(device)         \n",
    "alphas = 1 - betas                               \n",
    "alpha_bars = torch.cumprod(alphas, dim=0)   \n",
    "\n",
    "encoder = Encoder(latent_dim).to(device)\n",
    "decoder = Decoder(latent_dim).to(device)\n",
    "diffusion_prior = DiffusionPrior(latent_dim, time_embed_dim=time_embed_dim, hidden_dim=hidden_dim).to(device)\n",
    "\n",
    "optimizer = optim.Adam(list(encoder.parameters()) +\n",
    "                       list(decoder.parameters()) +\n",
    "                       list(diffusion_prior.parameters()), lr=1e-3)\n",
    "\n",
    "\n",
    "# Dataset (MNIST)   \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "real_folder = './real_images'\n",
    "os.makedirs(real_folder, exist_ok=True)\n",
    "count = 0\n",
    "for imgs, _ in test_loader:\n",
    "    for img in imgs:\n",
    "        utils.save_image(img, os.path.join(real_folder, f\"real_{count}.png\"))\n",
    "        count += 1\n",
    "        if count >= 500:\n",
    "            break\n",
    "    if count >= 500:\n",
    "        break \n",
    "\n",
    "# Loop de Treinamento       \n",
    "\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    diffusion_prior.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Encoder\n",
    "        mu, logvar = encoder(x)\n",
    "        z0 = reparameterize(mu, logvar)\n",
    "        \n",
    "        # Decoder\n",
    "        x_recon = decoder(z0)\n",
    "        recon_loss = F.binary_cross_entropy(x_recon, x, reduction='sum') / x.size(0)\n",
    "        \n",
    "        # Loss do DDPM no espaço latente\n",
    "        latent_loss = ddpm_loss(diffusion_prior, z0, betas, alpha_bars, T)\n",
    "        \n",
    "        loss = recon_loss + latent_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}] Batch {batch_idx}/{len(train_loader)} - Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Average Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pytorch-fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]C:\\Users\\leomi\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:09<00:00, 12.95s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:15<00:00, 13.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID: 50.95778229972345\n"
     ]
    }
   ],
   "source": [
    "\n",
    "############## Resultados ################\n",
    "# 1) Gerar 5 Imagens Aleatórias Geradas \n",
    "num_img = 5\n",
    "def generate_random_images(diffusion_prior, decoder, num_images, T, latent_dim, betas, alpha_bars, device):\n",
    "    images = []\n",
    "    for _ in range(num_images):\n",
    "        # Amostra um vetor latente via reverse diffusion\n",
    "        z = sample_latent(diffusion_prior, T, latent_dim, betas, alpha_bars, device)\n",
    "        # Gera a imagem usando o decoder\n",
    "        img = decoder(z)\n",
    "        images.append(img)\n",
    "    # Concatena em um grid para visualização\n",
    "    images = torch.cat(images, dim=0)\n",
    "    return images\n",
    "\n",
    "# Gerar 5 imagens e exibi-las\n",
    "diffusion_prior.eval()\n",
    "decoder.eval()\n",
    "with torch.no_grad():\n",
    "    imgs = generate_random_images(diffusion_prior, decoder, num_img, T, latent_dim, betas, alpha_bars, device)\n",
    "    \n",
    "# Exibir as 5 imagens (cada uma [1,28,28])\n",
    "imgs = imgs.cpu()\n",
    "grid_img = utils.make_grid(imgs, nrow=5)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(grid_img.permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(\"5 Imagens Geradas pelo Modelo\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 2) Calcular a Métrica FID\n",
    "\n",
    "# Salvar um conjunto de imagens geradas pelo modelo:\n",
    "fake_folder = './fake_images'\n",
    "os.makedirs(fake_folder, exist_ok=True)\n",
    "def save_images(images, folder, prefix):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    for i, img in enumerate(images):\n",
    "        # Salva cada imagem individualmente\n",
    "        utils.save_image(img, os.path.join(folder, f\"{prefix}_{i}.png\"))\n",
    "\n",
    "# Gerar um conjunto maior de imagens geradas (exemplo: 500 imagens)\n",
    "num_generated = 500\n",
    "generated_images = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_generated):\n",
    "        z = sample_latent(diffusion_prior, T, latent_dim, betas, alpha_bars, device)\n",
    "        img = decoder(z)\n",
    "        generated_images.append(img)\n",
    "generated_images = torch.cat(generated_images, dim=0)\n",
    "\n",
    "# Salva as imagens geradas\n",
    "save_images(generated_images, fake_folder, 'fake')\n",
    "\n",
    "# Calculando FID\n",
    "from pytorch_fid.fid_score import calculate_fid_given_paths\n",
    "\n",
    "# Defina os caminhos dos diretórios\n",
    "real_path = './real_images'\n",
    "fake_path = fake_folder\n",
    "\n",
    "# Calcular FID\n",
    "fid_value = calculate_fid_given_paths([real_path, fake_path], batch_size=50, device=device, dims=2048)\n",
    "print(f\"FID: {fid_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
